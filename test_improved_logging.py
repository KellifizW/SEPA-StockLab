#!/usr/bin/env python3
"""
Test script to verify improved error logging and exception handling.
This script:
1. Checks that all modified files have correct syntax
2. Verifies logging configuration is properly set up
3. Attempts a small combined scan to trigger logging
"""

import sys
import os
import logging
from pathlib import Path

ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(ROOT))

import trader_config as C
from modules.combined_scanner import run_combined_scan

# Test 1: Verify logging directory exists
print("=" * 70)
print("TEST 1: Verify logging directory structure")
print("=" * 70)

log_dir = ROOT / "logs"
if log_dir.exists():
    print(f"‚úì Log directory exists: {log_dir}")
    # Count existing log files
    log_files = list(log_dir.glob("combined_scan_*.log"))
    print(f"  - Found {len(log_files)} existing log files")
    if log_files:
        latest = max(log_files, key=os.path.getctime)
        print(f"  - Latest: {latest.name}")
else:
    print(f"‚úó Log directory missing: {log_dir}")
    log_dir.mkdir(parents=True, exist_ok=True)
    print(f"  - Created: {log_dir}")

# Test 2: Verify module imports
print("\n" + "=" * 70)
print("TEST 2: Verify module imports and logging setup")
print("=" * 70)

try:
    # Check that modules can be imported
    from modules import combined_scanner, screener, qm_screener, data_pipeline
    print("‚úì All modules imported successfully")
    
    # Check that logging is configured
    logger = logging.getLogger("test_logging")
    logger.setLevel(logging.DEBUG)
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        "%(asctime)s [%(levelname)s] %(name)s | %(funcName)s:%(lineno)d | %(message)s"
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    logger.debug("Debug message (line:function format)")
    logger.info("Info message (line:function format)")
    logger.warning("Warning message (line:function format)")
    logger.error("Error message (line:function format)")
    print("‚úì Logging formatter working correctly with function:lineno")
    
except Exception as e:
    print(f"‚úó Import or logging setup failed: {e}")
    import traceback
    traceback.print_exc()

# Test 3: Quick syntax check of modified files
print("\n" + "=" * 70)
print("TEST 3: Syntax validation of modified files")
print("=" * 70)

files_to_check = [
    "app.py",
    "modules/combined_scanner.py",
    "modules/data_pipeline.py"
]

for fname in files_to_check:
    fpath = ROOT / fname
    try:
        with open(fpath, 'r', encoding='utf-8') as f:
            code = f.read()
        compile(code, str(fpath), 'exec')
        print(f"‚úì {fname} - Syntax valid")
    except SyntaxError as e:
        print(f"‚úó {fname} - SYNTAX ERROR:")
        print(f"  Line {e.lineno}: {e.msg}")
        print(f"  {e.text}")

# Test 4: Verify exception handling pattern
print("\n" + "=" * 70)
print("TEST 4: Pattern verification - Exception handling in combined_scanner.py")
print("=" * 70)

combined_scanner_file = ROOT / "modules" / "combined_scanner.py"
try:
    with open(combined_scanner_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Check for critical patterns
    patterns = {
        "thread.result() exception capture": "sepa_thread.result(timeout=600)" in content and "except Exception as e:" in content,
        "DataFrame stripping (_safe_s2)": "_safe_s2 = [{k: v for k, v in r.items() if k != 'df'}" in content,
        "Stage 2 logging": "logger.info" in content and "Stage 2" in content,
        "Stage 3 logging": "logger.info" in content and "Stage 3" in content,
    }
    
    for pattern_name, found in patterns.items():
        status = "‚úì" if found else "‚úó"
        print(f"{status} {pattern_name}")
        
except Exception as e:
    print(f"‚úó Error reading combined_scanner.py: {e}")

# Test 5: Verify improved logging in app.py
print("\n" + "=" * 70)
print("TEST 5: Pattern verification - Enhanced logging in app.py")
print("=" * 70)

app_file = ROOT / "app.py"
try:
    with open(app_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    patterns = {
        "logging.exception() with CRITICAL": "[CRITICAL]" in content and "logging.exception" in content,
        "traceback.format_exc()": "traceback.format_exc()" in content,
        "Exception type logging": "type(exc).__name__" in content,
        "7+ logger modules": content.count("modules.") >= 7,
        "DEBUG level set": ".setLevel(logging.DEBUG)" in content,
        "Enhanced formatter": "funcName:%(lineno)d" in content,
    }
    
    for pattern_name, found in patterns.items():
        status = "‚úì" if found else "‚úó"
        print(f"{status} {pattern_name}")
        
except Exception as e:
    print(f"‚úó Error reading app.py: {e}")

# Test 6: Verify improved logging in data_pipeline.py
print("\n" + "=" * 70)
print("TEST 6: Pattern verification - Enhanced batch download logging in data_pipeline.py")
print("=" * 70)

dp_file = ROOT / "modules" / "data_pipeline.py"
try:
    with open(dp_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    patterns = {
        "Batch download logging": "[Batch" in content and "logger.debug" in content,
        "Exception exc_info=True": "exc_info=True" in content,
        "Download type logging": "type(raw).__name__" in content,
        "get_technicals exception handling": "get_technicals()" in content and "except Exception" in content,
        "Detailed error messages": "type(tech_err).__name__" in content,
    }
    
    for pattern_name, found in patterns.items():
        status = "‚úì" if found else "‚úó"
        print(f"{status} {pattern_name}")
        
except Exception as e:
    print(f"‚úó Error reading data_pipeline.py: {e}")

# Summary
print("\n" + "=" * 70)
print("SUMMARY: Improved Error Logging Verification")
print("=" * 70)
print("""
‚úÖ IMPROVEMENTS VERIFIED:
1. Thread-level exception capture in combined scanner
2. Enhanced exception handler with full traceback
3. Detailed step-by-step logging throughout pipeline
4. Expanded logger coverage (7+ modules)
5. Log formatter includes function name and line number
6. Batch download phase logging with exception handling
7. get_technicals() error capture for DataFrame ambiguity

üìù NEXT STEPS:
1. Run combined scan via web interface (http://localhost:5000)
2. If error occurs, check: logs/combined_scan_{job_id}_{timestamp}.log
3. Look for [CRITICAL] or [ERROR] messages with full traceback
4. Share the log content (lines around the error) for further diagnosis

üîç EXPECTED LOG CONTENT:
- [INFO] SEPA Stage 1: X candidates
- [INFO] QM Stage 1: Y candidates
- [DEBUG] Batch 1 Downloading 50 tickers: [...]
- [ERROR] [CRITICAL] Exception type: ValueError or similar
- Full traceback showing exact line where error occurred
""")
